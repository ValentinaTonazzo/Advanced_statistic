---
title: "final_project"
author: "Tonazzo Valentina"
date: '2022-07-07'
output: html_document
---

```{r}
df <- read.csv("train.csv", header = TRUE)
str(df)
```



```{r}
library(dplyr)
library(tidytext)
df$Text <- gsub(x = df$Text, pattern = "[0-9]+|[[:punct:]]|\\(.*\\)", replacement = "")   #serve per togliere i numeri, la punteggiatura e le parentesi ecc..
```







```{r}
#create token---> trasforma il testo in liste di parole, un'alternativa è la funzione unnest_tokens() 
library(tokenizers)
df$Text <- tokenize_words(df$Text)
#typeof(df$Text[[1]]) #prova è una lista in cui ogni elemento è una lista di characters
```

```{r}
library("stopwords")
SW = stopwords("en", source = "stopwords-iso")
my_func <- function(lista1, lista2 = SW){lista <- setdiff(lista1, lista2)}
df$Text <- lapply(df$Text[], my_func)
```

```{r}
#sentences <- df$[1:length(prova)]
N <- length(df$Text)  #tot number of texts
C <- sort(df$Labels[!duplicated(df$Labels)]) #single labels
#Ni <- aggregate(x = df, by = df$Labels, FUN = count)   <- per farlo senza il for
```




```{r}

#creation of the vocabulary

vocabulary <- c()                 #EVENTUALMENTE DA OTTIMIZZARE: raggrupo in un'unica lista tutti i testi insieme 
  for (j in 1:N){
    vocabulary <- c(vocabulary,  df$Text[[j]])
  }
 print(str(vocabulary))

 x <- factor(vocabulary)
 #vocabulary <- vocabulary[!duplicated(vocabulary)]   #si potrebbe usare dei factor per ottimizzare 
 #print(str(vocabulary))
```

```{r}
#table(x)
```



```{r}
#the algorithm 
library(dplyr)

for (c in C) {
  
  dfi <- filter(df, Labels == c)  #dataframe contenente tutti e soli i testi appartenenti alla stessa label
  Ni <- length(dfi$Text)         #numero totale di questi testi
  prior_i <- Ni/N              #prior uniforme per l'i-esima label
  
  textc <- c()                 #EVENTUALMENTE DA OTTIMIZZARE: raggrupo in un'unica lista tutti i testi insieme 
  for (j in 1:length(dfi$Text)){
    textc <- c(textc,  dfi$Text[[j]])
  }
  #print( str(textc) )
  
  
  
}
  

```


```















